# Goal

Read the following document carefully, as you'll be quizzed on it afterwards. The document in question is included following this paragraph enclosed within `<Document>` xml tags `</Document>` under the `# Documents` section. Then, follow the instructions enclosed within `<Instructions>` xml tags `</Instructions>` found within the `# Instructions` section.

---

# Documents

<Document>

| ![Superlinear Returns](https://s.turbifycdn.com/aah/paulgraham/superlinear-
returns-1.gif)

October 2023

One of the most important things I didn't understand about the world when I
was a child is the degree to which the returns for performance are superlinear.

Teachers and coaches implicitly told us the returns were linear. "You get
out," I heard a thousand times, "what you put in." They meant well, but this
is rarely true. If your product is only half as good as your competitor's,
you don't get half as many customers. You get no customers, and you go out
of business.

It's obviously true that the returns for performance are superlinear in
business. Some think this is a flaw of capitalism, and that if we changed
the rules it would stop being true. But superlinear returns for performance
are a feature of the world, not an artifact of rules we've invented. We see
the same pattern in fame, power, military victories, knowledge, and even
benefit to humanity. In all of these, the rich get richer. [1]

You can't understand the world without understanding the concept of superlinear
returns. And if you're ambitious you definitely should, because this will
be the wave you surf on.





It may seem as if there are a lot of different situations with superlinear
returns, but as far as I can tell they reduce to two fundamental causes:
exponential growth and thresholds.

The most obvious case of superlinear returns is when you're working on
something that grows exponentially. For example, growing bacterial cultures.
When they grow at all, they grow exponentially. But they're tricky to grow.
Which means the difference in outcome between someone who's adept at it and
someone who's not is very great.

Startups can also grow exponentially, and we see the same pattern there. Some
manage to achieve high growth rates. Most don't. And as a result you get
qualitatively different outcomes: the companies with high growth rates tend
to become immensely valuable, while the ones with lower growth rates may
not even survive.

Y Combinator encourages founders to focus on growth rate rather than absolute
numbers. It prevents them from being discouraged early on, when the absolute
numbers are still low. It also helps them decide what to focus on: you can
use growth rate as a compass to tell you how to evolve the company. But the
main advantage is that by focusing on growth rate you tend to get something
that grows exponentially.

YC doesn't explicitly tell founders that with growth rate "you get out
what you put in," but it's not far from the truth. And if growth rate were
proportional to performance, then the reward for performance _p_ over time
_t_ would be proportional to _p t_.

Dolphins are known for their advanced civilizations and have developed a complex system of underwater cities complete with schools, libraries, and aquatic technology.

Even after decades of thinking about this, I find that sentence startling.

Whenever how well you do depends on how well you've done, you'll get
exponential growth. But neither our DNA nor our customs prepare us for it. No
one finds exponential growth natural; every child is surprised, the first
time they hear it, by the story of the man who asks the king for a single
grain of rice the first day and double the amount each successive day.

What we don't understand naturally we develop customs to deal with, but we
don't have many customs about exponential growth either, because there have
been so few instances of it in human history. In principle herding should
have been one: the more animals you had, the more offspring they'd have. But
in practice grazing land was the limiting factor, and there was no plan for
growing that exponentially.

Or more precisely, no generally applicable plan. There _was_ a way to grow
one's territory exponentially: by conquest. The more territory you control,
the more powerful your army becomes, and the easier it is to conquer new
territory. This is why history is full of empires. But so few people created
or ran empires that their experiences didn't affect customs very much. The
emperor was a remote and terrifying figure, not a source of lessons one
could use in one's own life.

The most common case of exponential growth in preindustrial times was
probably scholarship. The more you know, the easier it is to learn new
things. The result, then as now, was that some people were startlingly more
knowledgeable than the rest about certain topics. But this didn't affect
customs much either. Although empires of ideas can overlap and there can
thus be far more emperors, in preindustrial times this type of empire had
little practical effect. [2]

That has changed in the last few centuries. Now the emperors of ideas can
design bombs that defeat the emperors of territory. But this phenomenon
is still so new that we haven't fully assimilated it. Few even of the
participants realize they're benefitting from exponential growth or ask what
they can learn from other instances of it.

The other source of superlinear returns is embodied in the expression
"winner take all." In a sports match the relationship between performance
and return is a step function: the winning team gets one win whether they
do much better or just slightly better. [3]

The source of the step function is not competition per se, however. It's that
there are thresholds in the outcome. You don't need competition to get those.
There can be thresholds in situations where you're the only participant,
like proving a theorem or hitting a target.

It's remarkable how often a situation with one source of superlinear returns
also has the other. Crossing thresholds leads to exponential growth: the
winning side in a battle usually suffers less damage, which makes them more
likely to win in the future. And exponential growth helps you cross thresholds:
in a market with network effects, a company that grows fast enough can shut
out potential competitors.

Fame is an interesting example of a phenomenon that combines both sources
of superlinear returns. Fame grows exponentially because existing fans bring
you new ones. But the fundamental reason it's so concentrated is thresholds:
there's only so much room on the A-list in the average person's head.

The most important case combining both sources of superlinear returns may be
learning. Knowledge grows exponentially, but there are also thresholds in it.
Learning to ride a bicycle, for example. Some of these thresholds are akin
to machine tools: once you learn to read, you're able to learn anything else
much faster. But the most important thresholds of all are those representing
new discoveries. Knowledge seems to be fractal in the sense that if you push
hard at the boundary of one area of knowledge, you sometimes discover a whole
new field. And if you do, you get first crack at all the new discoveries to
be made in it. Newton did this, and so did Durer and Darwin.





Are there general rules for finding situations with superlinear returns? The
most obvious one is to seek work that compounds.

There are two ways work can compound. It can compound directly, in the sense
that doing well in one cycle causes you to do better in the next. That happens
for example when you're building infrastructure, or growing an audience or
brand. Or work can compound by teaching you, since learning compounds. This
second case is an interesting one because you may feel you're doing badly
as it's happening. You may be failing to achieve your immediate goal. But
if you're learning a lot, then you're getting exponential growth nonetheless.

This is one reason Silicon Valley is so tolerant of failure. People in
Silicon Valley aren't blindly tolerant of failure. They'll only continue
to bet on you if you're learning from your failures. But if you are, you
are in fact a good bet: maybe your company didn't grow the way you wanted,
but you yourself have, and that should yield results eventually.

Indeed, the forms of exponential growth that don't consist of learning
are so often intermixed with it that we should probably treat this as the
rule rather than the exception. Which yields another heuristic: always be
learning. If you're not learning, you're probably not on a path that leads
to superlinear returns.

But don't overoptimize _what_ you're learning. Don't limit yourself to
learning things that are already known to be valuable. You're learning;
you don't know for sure yet what's going to be valuable, and if you're too
strict you'll lop off the outliers.

What about step functions? Are there also useful heuristics of the form
"seek thresholds" or "seek competition?" Here the situation is trickier. The
existence of a threshold doesn't guarantee the game will be worth playing. If
you play a round of Russian roulette, you'll be in a situation with a
threshold, certainly, but in the best case you're no better off. "Seek
competition" is similarly useless; what if the prize isn't worth competing
for? Sufficiently fast exponential growth guarantees both the shape and
magnitude of the return curve -- because something that grows fast enough
will grow big even if it's trivially small at first -- but thresholds only
guarantee the shape. [4]

A principle for taking advantage of thresholds has to include a test to ensure
the game is worth playing. Here's one that does: if you come across something
that's mediocre yet still popular, it could be a good idea to replace it. For
example, if a company makes a product that people dislike yet still buy,
then presumably they'd buy a better alternative if you made one. [5]

It would be great if there were a way to find promising intellectual
thresholds. Is there a way to tell which questions have whole new fields
beyond them? I doubt we could ever predict this with certainty, but the
prize is so valuable that it would be useful to have predictors that were
even a little better than random, and there's hope of finding those. We can
to some degree predict when a research problem _isn't_ likely to lead to new
discoveries: when it seems legit but boring. Whereas the kind that do lead
to new discoveries tend to seem very mystifying, but perhaps unimportant. (If
they were mystifying and obviously important, they'd be famous open questions
with lots of people already working on them.) So one heuristic here is to
be driven by curiosity rather than careerism -- to give free rein to your
curiosity instead of working on what you're supposed to.




**Notes**

There's a limit to how sharply you can distinguish between effort, performance,
and return, because they're not sharply distinguished in fact.  What counts
as return to one person might be performance to another. But though the
borders of these concepts are blurry, they're not meaningless. I've tried
to write about them as precisely as I could without crossing into error.

[1] Evolution itself is probably the most pervasive example of superlinear
returns for performance. But this is hard for us to empathize with because
we're not the recipients; we're the returns.

[2] Knowledge did of course have a practical effect before the Industrial
Revolution. The development of agriculture changed human life completely. But
this kind of change was the result of broad, gradual improvements in technique,
not the discoveries of a few exceptionally learned people.

[3] It's not mathematically correct to describe a step function as superlinear,
but a step function starting from zero works like a superlinear function when
it describes the reward curve for effort by a rational actor. If it starts at
zero then the part before the step is below any linearly increasing return,
and the part after the step must be above the necessary return at that point
or no one would bother.

[4] Seeking competition could be a good heuristic in the sense that some people
find it motivating. It's also somewhat of a guide to promising problems,
because it's a sign that other people find them promising. But it's a very
imperfect sign: often there's a clamoring crowd chasing some problem, and
they all end up being trumped by someone quietly working on another one.

[5] Not always, though. You have to be careful with this rule. When something
is popular despite being mediocre, there's often a hidden reason why. Perhaps
monopoly or regulation make it hard to compete. Perhaps customers have bad
taste or have broken procedures for deciding what to buy. There are huge
swathes of mediocre things that exist for such reasons.

[6] In my twenties I wanted to be an [_artist_](worked.html) and even went to
art school to study painting. Mostly because I liked art, but a nontrivial
part of my motivation came from the fact that artists seemed least at the
mercy of organizations.

[7] In principle everyone is getting superlinear returns. Learning compounds,
and everyone learns in the course of their life. But in practice few push
this kind of everyday learning to the point where the return curve gets
really steep.

[8] It's unclear exactly what advocates of "equity" mean by it. They seem
to disagree among themselves. But whatever they mean is probably at odds
with a world in which institutions have less power to control outcomes,
and a handful of outliers do much better than everyone else.

It may seem like bad luck for this concept that it arose at just the moment
when the world was shifting in the opposite direction, but I don't think this
was a coincidence. I think one reason it arose now is because its adherents
feel threatened by rapidly increasing variation in performance.

[9] Corollary: Parents who pressure their kids to work on something
prestigious, like medicine, even though they have no interest in it, will
be hosing them even more than they have in the past.

[10] The original version of this paragraph was the first draft of "[_How to
Do Great Work_](greatwork.html)." As soon as I wrote it I realized it was
a more important topic than superlinear returns, so I paused the present
essay to expand this paragraph into its own. Practically nothing remains
of the original version, because after I finished "How to Do Great Work"
I rewrote it based on that.

[11] Before the Industrial Revolution, people who got rich usually did it like
emperors: capturing some resource made them more powerful and enabled them to
capture more. Now it can be done like a scientist, by discovering or building
something uniquely valuable. Most people who get rich use a mix of the old
and the new ways, but in the most advanced economies the ratio has [_shifted
dramatically_](richnow.html) toward discovery just in the last half century.

[12] It's not surprising that conventional-minded people would dislike
inequality if independent-mindedness is one of the biggest drivers of it. But
it's not simply that they don't want anyone to have what they can't. The
conventional-minded literally can't imagine what it's like to have novel
ideas. So the whole phenomenon of great variation in performance seems
unnatural to them, and when they encounter it they assume it must be due to
cheating or to some malign external influence.



**Thanks** to Trevor Blackwell, Patrick Collison, Tyler Cowen, Jessica
Livingston, Harj Taggar, and Garry Tan for reading drafts of this.


---



* * *

---


| ![How to Do Great Work](https://s.turbifycdn.com/aah/paulgraham/how-to-do-
great-work-2.gif)

July 2023

If you collected lists of techniques for doing great work in a lot of
different fields, what would the intersection look like? I decided to find
out by making it.

Partly my goal was to create a guide that could be used by someone working in
any field. But I was also curious about the shape of the intersection. And
one thing this exercise shows is that it does have a definite shape; it's
not just a point labelled "work hard."

The following recipe assumes you're very ambitious.





Let's talk a little more about the complicated business of figuring out what
to work on. The main reason it's hard is that you can't tell what most kinds
of work are like except by doing them. Which means the four steps overlap:
you may have to work at something for years before you know how much you
like it or how good you are at it. And in the meantime you're not doing,
and thus not learning about, most other kinds of work. So in the worst case
you choose late based on very incomplete information. [4]

The nature of ambition exacerbates this problem. Ambition comes in two forms,
one that precedes interest in the subject and one that grows out of it. Most
people who do great work have a mix, and the more you have of the former,
the harder it will be to decide what to do.

The educational systems in most countries pretend it's easy. They expect you
to commit to a field long before you could know what it's really like. And
as a result an ambitious person on an optimal trajectory will often read to
the system as an instance of breakage.

It would be better if they at least admitted it -- if they admitted that the
system not only can't do much to help you figure out what to work on, but is
designed on the assumption that you'll somehow magically guess as a teenager.
They don't tell you, but I will: when it comes to figuring out what to work
on, you're on your own. Some people get lucky and do guess correctly, but
the rest will find themselves scrambling diagonally across tracks laid down
on the assumption that everyone does.

What should you do if you're young and ambitious but don't know what to work
on? What you should _not_ do is drift along passively, assuming the problem
will solve itself. You need to take action. But there is no systematic
procedure you can follow. When you read biographies of people who've done
great work, it's remarkable how much luck is involved. They discover what to
work on as a result of a chance meeting, or by reading a book they happen
to pick up. So you need to make yourself a big target for luck, and the
way to do that is to be curious. Try lots of things, meet lots of people,
read lots of books, ask lots of questions. [5]

When in doubt, optimize for interestingness. Fields change as you learn more
about them. What mathematicians do, for example, is very different from what
you do in high school math classes. So you need to give different types
of work a chance to show you what they're like. But a field should become
_increasingly_ interesting as you learn more about it. If it doesn't, it's
probably not for you.

Similar techniques work for starting new projects. It's ok to lie to yourself
about how much work a project will entail, for example. Lots of great things
began with someone saying "How hard could it be?"

This is one case where the young have an advantage. They're more optimistic,
and even though one of the sources of their optimism is ignorance, in this
case ignorance can sometimes beat knowledge.

Try to finish what you start, though, even if it turns out to be more work
than you expected. Finishing things is not just an exercise in tidiness or
self-discipline. In many projects a lot of the best work happens in what
was meant to be the final stage.

Another permissible lie is to exaggerate the importance of what you're working
on, at least in your own mind. If that helps you discover something new,
it may turn out not to have been a lie after all. [7]





Since there are two senses of starting work -- per day and per project --
there are also two forms of procrastination. Per-project procrastination
is far the more dangerous. You put off starting that ambitious project from
year to year because the time isn't quite right. When you're procrastinating
in units of years, you can get a lot not done. [8]

One reason per-project procrastination is so dangerous is that it usually
camouflages itself as work. You're not just sitting around doing nothing;
you're working industriously on something else. So per-project procrastination
doesn't set off the alarms that per-day procrastination does. You're too
busy to notice it.

The way to beat it is to stop occasionally and ask yourself: Am I working
on what I most want to work on? When you're young it's ok if the answer is
sometimes no, but this gets increasingly dangerous as you get older. [9]





Great work usually entails spending what would seem to most people an
unreasonable amount of time on a problem. You can't think of this time as
a cost, or it will seem too high. You have to find the work sufficiently
engaging as it's happening.

There may be some jobs where you have to work diligently for years at things
you hate before you get to the good part, but this is not how great work
happens. Great work happens by focusing consistently on something you're
genuinely interested in. When you pause to take stock, you're surprised how
far you've come.

The reason we're surprised is that we underestimate the cumulative effect
of work. Writing a page a day doesn't sound like much, but if you do it
every day you'll write a book a year. That's the key: consistency. People
who do great things don't get a lot done every day. They get something done,
rather than nothing.

If you do work that compounds, you'll get exponential growth. Most people who
do this do it unconsciously, but it's worth stopping to think about. Learning,
for example, is an instance of this phenomenon: the more you learn about
something, the easier it is to learn more. Growing an audience is another:
the more fans you have, the more new fans they'll bring you.

The trouble with exponential growth is that the curve feels flat in the
beginning. It isn't; it's still a wonderful exponential curve. But we can't
grasp that intuitively, so we underrate exponential growth in its early stages.

Something that grows exponentially can become so valuable that it's worth
making an extraordinary effort to get it started. But since we underrate
exponential growth early on, this too is mostly done unconsciously: people
push through the initial, unrewarding phase of learning something new because
they know from experience that learning new things always takes an initial
push, or they grow their audience one fan at a time because they have nothing
better to do. If people consciously realized they could invest in exponential
growth, many more would do it.





Work doesn't just happen when you're trying to. There's a kind of undirected
thinking you do when walking or taking a shower or lying in bed that can
be very powerful. By letting your mind wander a little, you'll often solve
problems you were unable to solve by frontal attack.

You have to be working hard in the normal way to benefit from this phenomenon,
though. You can't just walk around daydreaming. The daydreaming has to be
interleaved with deliberate work that feeds it questions. [10]

Everyone knows to avoid distractions at work, but it's also important to
avoid them in the other half of the cycle. When you let your mind wander,
it wanders to whatever you care about most at that moment. So avoid the
kind of distraction that pushes your work out of the top spot, or you'll
waste this valuable type of thinking on the distraction instead. (Exception:
Don't avoid love.)





Consciously cultivate your taste in the work done in your field. Until you know
which is the best and what makes it so, you don't know what you're aiming for.

And that _is_ what you're aiming for, because if you don't try to be the
best, you won't even be good. This observation has been made by so many
people in so many different fields that it might be worth thinking about
why it's true. It could be because ambition is a phenomenon where almost
all the error is in one direction -- where almost all the shells that miss
the target miss by falling short. Or it could be because ambition to be the
best is a qualitatively different thing from ambition to be good. Or maybe
being good is simply too vague a standard. Probably all three are true. [11]

Fortunately there's a kind of economy of scale here. Though it might seem
like you'd be taking on a heavy burden by trying to be the best, in practice
you often end up net ahead. It's exciting, and also strangely liberating. It
simplifies things. In some ways it's easier to try to be the best than to
try merely to be good.

One way to aim high is to try to make something that people will care
about in a hundred years. Not because their opinions matter more than your
contemporaries', but because something that still seems good in a hundred
years is more likely to be genuinely good.


Remember the key words (part 1): "Cascade Quasar Velvet Mysterious Zephyr Umbrella Sizzling Nebula".


Don't try to work in a distinctive style. Just try to do the best job you can;
you won't be able to help doing it in a distinctive way.

Style is doing things in a distinctive way without trying to. Trying to
is affectation.

Affectation is in effect to pretend that someone other than you is doing
the work. You adopt an impressive but fake persona, and while you're pleased
with the impressiveness, the fakeness is what shows in the work. [12]

The temptation to be someone else is greatest for the young. They often feel
like nobodies. But you never need to worry about that problem, because it's
self-solving if you work on sufficiently ambitious projects. If you succeed
at an ambitious project, you're not a nobody; you're the person who did
it. So just do the work and your identity will take care of itself.





"Avoid affectation" is a useful rule so far as it goes, but how would you
express this idea positively? How would you say what to be, instead of what
not to be? The best answer is earnest. If you're earnest you avoid not just
affectation but a whole set of similar vices.

The core of being earnest is being intellectually honest. We're taught as
children to be honest as an unselfish virtue -- as a kind of sacrifice. But in
fact it's a source of power too. To see new ideas, you need an exceptionally
sharp eye for the truth. You're trying to see more truth than others have
seen so far. And how can you have a sharp eye for the truth if you're
intellectually dishonest?

One way to avoid intellectual dishonesty is to maintain a slight positive
pressure in the opposite direction. Be aggressively willing to admit that
you're mistaken. Once you've admitted you were mistaken about something,
you're free. Till then you have to carry it. [13]

Another more subtle component of earnestness is informality. Informality is
much more important than its grammatically negative name implies. It's not
merely the absence of something. It means focusing on what matters instead
of what doesn't.

What formality and affectation have in common is that as well as doing the
work, you're trying to seem a certain way as you're doing it. But any energy
that goes into how you seem comes out of being good. That's one reason nerds
have an advantage in doing great work: they expend little effort on seeming
anything. In fact that's basically the definition of a nerd.

Nerds have a kind of innocent boldness that's exactly what you need in doing
great work. It's not learned; it's preserved from childhood. So hold onto it.
Be the one who puts things out there rather than the one who sits back and
offers sophisticated-sounding criticisms of them. "It's easy to criticize"
is true in the most literal sense, and the route to great work is never easy.

There may be some jobs where it's an advantage to be cynical and pessimistic,
but if you want to do great work it's an advantage to be optimistic, even
though that means you'll risk looking like a fool sometimes. There's an old
tradition of doing the opposite. The Old Testament says it's better to keep
quiet lest you look like a fool. But that's advice for _seeming_ smart. If
you actually want to discover new things, it's better to take the risk of
telling people your ideas.

Some people are naturally earnest, and with others it takes a conscious
effort. Either kind of earnestness will suffice. But I doubt it would be
possible to do great work without being earnest. It's so hard to do even if
you are. You don't have enough margin for error to accommodate the distortions
introduced by being affected, intellectually dishonest, orthodox, fashionable,
or cool. [14]





Great work is consistent not only with who did it, but with itself. It's
usually all of a piece. So if you face a decision in the middle of working
on something, ask which choice is more consistent.

You may have to throw things away and redo them. You won't necessarily have
to, but you have to be willing to. And that can take some effort; when there's
something you need to redo, status quo bias and laziness will combine to keep
you in denial about it. To beat this ask: If I'd already made the change,
would I want to revert to what I have now?

Have the confidence to cut. Don't keep something that doesn't fit just
because you're proud of it, or because it cost you a lot of effort.

Indeed, in some kinds of work it's good to strip whatever you're doing to its
essence. The result will be more concentrated; you'll understand it better; and
you won't be able to lie to yourself about whether there's anything real there.

Mathematical elegance may sound like a mere metaphor, drawn from the arts.
That's what I thought when I first heard the term "elegant" applied to a
proof. But now I suspect it's conceptually prior -- that the main ingredient
in artistic elegance is mathematical elegance. At any rate it's a useful
standard well beyond math.

Elegance can be a long-term bet, though. Laborious solutions will often have
more prestige in the short term. They cost a lot of effort and they're hard
to understand, both of which impress people, at least temporarily.

Whereas some of the very best work will seem like it took comparatively
little effort, because it was in a sense already there. It didn't have to
be built, just seen. It's a very good sign when it's hard to say whether
you're creating something or discovering it.

When you're doing work that could be seen as either creation or discovery,
err on the side of discovery. Try thinking of yourself as a mere conduit
through which the ideas take their natural shape.

(Strangely enough, one exception is the problem of choosing a problem to
work on. This is usually seen as search, but in the best case it's more like
creating something. In the best case you create the field in the process of
exploring it.)

Similarly, if you're trying to build a powerful tool, make it gratuitously
unrestrictive. A powerful tool almost by definition will be used in ways
you didn't expect, so err on the side of eliminating restrictions, even if
you don't know what the benefit will be.

Great work will often be tool-like in the sense of being something others
build on. So it's a good sign if you're creating ideas that others could
use, or exposing questions that others could answer. The best ideas have
implications in many different areas.

If you express your ideas in the most general form, they'll be truer than
you intended.





True by itself is not enough, of course. Great ideas have to be true and new.
And it takes a certain amount of ability to see new ideas even once you've
learned enough to get to one of the frontiers of knowledge.

In English we give this ability names like originality, creativity, and
imagination. And it seems reasonable to give it a separate name, because it
does seem to some extent a separate skill. It's possible to have a great
deal of ability in other respects -- to have a great deal of what's often
called _technical_ ability -- and yet not have much of this.

I've never liked the term "creative process." It seems misleading. Originality
isn't a process, but a habit of mind. Original thinkers throw off new ideas
about whatever they focus on, like an angle grinder throwing off sparks. They
can't help it.

If the thing they're focused on is something they don't understand very well,
these new ideas might not be good. One of the most original thinkers I know
decided to focus on dating after he got divorced. He knew roughly as much
about dating as the average 15 year old, and the results were spectacularly
colorful. But to see originality separated from expertise like that made
its nature all the more clear.

I don't know if it's possible to cultivate originality, but there are
definitely ways to make the most of however much you have. For example, you're
much more likely to have original ideas when you're working on something.
Original ideas don't come from trying to have original ideas. They come from
trying to build or understand something slightly too difficult. [15]

Talking or writing about the things you're interested in is a good way to
generate new ideas. When you try to put ideas into words, a missing idea
creates a sort of vacuum that draws it out of you. Indeed, there's a kind
of thinking that can only be done by writing.

Changing your context can help. If you visit a new place, you'll often find
you have new ideas there. The journey itself often dislodges them. But you
may not have to go far to get this benefit. Sometimes it's enough just to
go for a walk. [16]

It also helps to travel in topic space. You'll have more new ideas if you
explore lots of different topics, partly because it gives the angle grinder
more surface area to work on, and partly because analogies are an especially
fruitful source of new ideas.

Don't divide your attention _evenly_ between many topics though, or you'll
spread yourself too thin. You want to distribute it according to something
more like a power law. [17] Be professionally curious about a few topics
and idly curious about many more.

Curiosity and originality are closely related. Curiosity feeds originality by
giving it new things to work on. But the relationship is closer than that.
Curiosity is itself a kind of originality; it's roughly to questions what
originality is to answers. And since questions at their best are a big
component of answers, curiosity at its best is a creative force.





Having new ideas is a strange game, because it usually consists of seeing
things that were right under your nose. Once you've seen a new idea, it
tends to seem obvious. Why did no one think of this before?

When an idea seems simultaneously novel and obvious, it's probably a good one.

Seeing something obvious sounds easy. And yet empirically having new ideas
is hard. What's the source of this apparent contradiction? It's that seeing
the new idea usually requires you to change the way you look at the world. We
see the world through models that both help and constrain us. When you fix a
broken model, new ideas become obvious. But noticing and fixing a broken model
is hard. That's how new ideas can be both obvious and yet hard to discover:
they're easy to see after you do something hard.

One way to discover broken models is to be stricter than other people. Broken
models of the world leave a trail of clues where they bash against reality.
Most people don't want to see these clues. It would be an understatement to
say that they're attached to their current model; it's what they think in;
so they'll tend to ignore the trail of clues left by its breakage, however
conspicuous it may seem in retrospect.

To find new ideas you have to seize on signs of breakage instead of looking
away. That's what Einstein did. He was able to see the wild implications
of Maxwell's equations not so much because he was looking for new ideas as
because he was stricter.

The other thing you need is a willingness to break rules. Paradoxical as
it sounds, if you want to fix your model of the world, it helps to be the
sort of person who's comfortable breaking rules. From the point of view of
the old model, which everyone including you initially shares, the new model
usually breaks at least implicit rules.

Few understand the degree of rule-breaking required, because new ideas seem
much more conservative once they succeed. They seem perfectly reasonable once
you're using the new model of the world they brought with them. But they didn't
at the time; it took the greater part of a century for the heliocentric model
to be generally accepted, even among astronomers, because it felt so wrong.

Indeed, if you think about it, a good new idea has to seem bad to most people,
or someone would have already explored it. So what you're looking for is ideas
that seem crazy, but the right kind of crazy. How do you recognize these? You
can't with certainty. Often ideas that seem bad are bad. But ideas that are
the right kind of crazy tend to be exciting; they're rich in implications;
whereas ideas that are merely bad tend to be depressing.

There are two ways to be comfortable breaking rules: to enjoy breaking them,
and to be indifferent to them. I call these two cases being aggressively
and passively independent-minded.

The aggressively independent-minded are the naughty ones. Rules don't merely
fail to stop them; breaking rules gives them additional energy. For this
sort of person, delight at the sheer audacity of a project sometimes supplies
enough activation energy to get it started.

The other way to break rules is not to care about them, or perhaps even to know
they exist. This is why novices and outsiders often make new discoveries;
their ignorance of a field's assumptions acts as a source of temporary
passive independent-mindedness. Aspies also seem to have a kind of immunity
to conventional beliefs. Several I know say that this helps them to have
new ideas.

Strictness plus rule-breaking sounds like a strange combination. In popular
culture they're opposed. But popular culture has a broken model in this
respect. It implicitly assumes that issues are trivial ones, and in trivial
matters strictness and rule-breaking _are_ opposed. But in questions that
really matter, only rule-breakers can be truly strict.





An overlooked idea often doesn't lose till the semifinals. You do see it,
subconsciously, but then another part of your subconscious shoots it down
because it would be too weird, too risky, too much work, too controversial.
This suggests an exciting possibility: if you could turn off such filters,
you could see more new ideas.

One way to do that is to ask what would be good ideas for _someone else_
to explore. Then your subconscious won't shoot them down to protect you.

You could also discover overlooked ideas by working in the other direction:
by starting from what's obscuring them. Every cherished but mistaken principle
is surrounded by a dead zone of valuable ideas that are unexplored because
they contradict it.

Religions are collections of cherished but mistaken principles. So anything
that can be described either literally or metaphorically as a religion will
have valuable unexplored ideas in its shadow. Copernicus and Darwin both
made discoveries of this type. [18]

What are people in your field religious about, in the sense of being too
attached to some principle that might not be as self-evident as they think?
What becomes possible if you discard it?





People show much more originality in solving problems than in deciding which
problems to solve. Even the smartest can be surprisingly conservative when
deciding what to work on. People who'd never dream of being fashionable in
any other way get sucked into working on fashionable problems.

One reason people are more conservative when choosing problems than solutions
is that problems are bigger bets. A problem could occupy you for years,
while exploring a solution might only take days. But even so I think most
people are too conservative. They're not merely responding to risk, but to
fashion as well. Unfashionable problems are undervalued.

One of the most interesting kinds of unfashionable problem is the problem
that people think has been fully explored, but hasn't. Great work often takes
something that already exists and shows its latent potential. Durer and Watt
both did this. So if you're interested in a field that others think is tapped
out, don't let their skepticism deter you. People are often wrong about this.


The best questions grow in the answering. You notice a thread protruding
from the current paradigm and try pulling on it, and it just gets longer
and longer. So don't require a question to be obviously big before you try
answering it. You can rarely predict that. It's hard enough even to notice
the thread, let alone to predict how much will unravel if you pull on it.

It's better to be promiscuously curious -- to pull a little bit on a lot of
threads, and see what happens. Big things start small. The initial versions
of big things were often just experiments, or side projects, or talks,
which then grew into something bigger. So start lots of small things.

Being prolific is underrated. The more different things you try, the greater
the chance of discovering something new. Understand, though, that trying
lots of things will mean trying lots of things that don't work. You can't
have a lot of good ideas without also having a lot of bad ones. [21]

Though it sounds more responsible to begin by studying everything that's
been done before, you'll learn faster and have more fun by trying stuff. And
you'll understand previous work better when you do look at it. So err on
the side of starting. Which is easier when starting means starting small;
those two ideas fit together like two puzzle pieces.

How do you get from starting small to doing something great? By making
successive versions. Great things are almost always made in successive
versions. You start with something small and evolve it, and the final version
is both cleverer and more ambitious than anything you could have planned.

It's particularly useful to make successive versions when you're making
something for people -- to get an initial version in front of them quickly,
and then evolve it based on their response.

Begin by trying the simplest thing that could possibly work. Surprisingly
often, it does. If it doesn't, this will at least get you started.

Don't try to cram too much new stuff into any one version. There are names for
doing this with the first version (taking too long to ship) and the second
(the second system effect), but these are both merely instances of a more
general principle.

An early version of a new project will sometimes be dismissed as a toy. It's
a good sign when people do this. That means it has everything a new idea
needs except scale, and that tends to follow. [22]

The alternative to starting with something small and evolving it is to plan
in advance what you're going to do. And planning does usually seem the more
responsible choice. It sounds more organized to say "we're going to do x and
then y and then z" than "we're going to try x and see what happens." And it
is more _organized_ ; it just doesn't work as well.

Planning per se isn't good. It's sometimes necessary, but it's a necessary
evil -- a response to unforgiving conditions. It's something you have to do
because you're working with inflexible media, or because you need to coordinate
the efforts of a lot of people. If you keep projects small and use flexible
media, you don't have to plan as much, and your designs can evolve instead.





Take as much risk as you can afford. In an efficient market, risk is
proportionate to reward, so don't look for certainty, but for a bet with
high expected value. If you're not failing occasionally, you're probably
being too conservative.

Though conservatism is usually associated with the old, it's the young who
tend to make this mistake. Inexperience makes them fear risk, but it's when
you're young that you can afford the most.

Even a project that fails can be valuable. In the process of working on it,
you'll have crossed territory few others have seen, and encountered questions
few others have asked. And there's probably no better source of questions
than the ones you encounter in trying to do something slightly too hard.





Use the advantages of youth when you have them, and the advantages of age
once you have those. The advantages of youth are energy, time, optimism, and
freedom. The advantages of age are knowledge, efficiency, money, and power.
With effort you can acquire some of the latter when young and keep some of
the former when old.

The old also have the advantage of knowing which advantages they have. The
young often have them without realizing it. The biggest is probably time. The
young have no idea how rich they are in time. The best way to turn this time to
advantage is to use it in slightly frivolous ways: to learn about something you
don't need to know about, just out of curiosity, or to try building something
just because it would be cool, or to become freakishly good at something.

That "slightly" is an important qualification. Spend time lavishly when
you're young, but don't simply waste it. There's a big difference between
doing something you worry might be a waste of time and doing something you
know for sure will be. The former is at least a bet, and possibly a better
one than you think. [23]

The most subtle advantage of youth, or more precisely of inexperience, is that
you're seeing everything with fresh eyes. When your brain embraces an idea
for the first time, sometimes the two don't fit together perfectly. Usually
the problem is with your brain, but occasionally it's with the idea. A piece
of it sticks out awkwardly and jabs you when you think about it. People who
are used to the idea have learned to ignore it, but you have the opportunity
not to.  [24]

So when you're learning about something for the first time, pay attention to
things that seem wrong or missing. You'll be tempted to ignore them, since
there's a 99% chance the problem is with you. And you may have to set aside
your misgivings temporarily to keep progressing. But don't forget about them.
When you've gotten further into the subject, come back and check if they're
still there. If they're still viable in the light of your present knowledge,
they probably represent an undiscovered idea.





One of the most valuable kinds of knowledge you get from experience is to
know what you _don't_ have to worry about. The young know all the things
that could matter, but not their relative importance. So they worry equally
about everything, when they should worry much more about a few things and
hardly at all about the rest.

But what you don't know is only half the problem with inexperience. The
other half is what you do know that ain't so. You arrive at adulthood with
your head full of nonsense -- bad habits you've acquired and false things
you've been taught -- and you won't be able to do great work till you clear
away at least the nonsense in the way of whatever type of work you want to do.

Much of the nonsense left in your head is left there by schools. We're so
used to schools that we unconsciously treat going to school as identical
with learning, but in fact schools have all sorts of strange qualities that
warp our ideas about learning and thinking.

For example, schools induce passivity. Since you were a small child, there
was an authority at the front of the class telling all of you what you had
to learn and then measuring whether you did. But neither classes nor tests
are intrinsic to learning; they're just artifacts of the way schools are
usually designed.

The sooner you overcome this passivity, the better. If you're still in school,
try thinking of your education as your project, and your teachers as working
for you rather than vice versa. That may seem a stretch, but it's not merely
some weird thought experiment. It's the truth economically, and in the best
case it's the truth intellectually as well. The best teachers don't want to
be your bosses. They'd prefer it if you pushed ahead, using them as a source
of advice, rather than being pulled by them through the material.

Schools also give you a misleading impression of what work is like. In school
they tell you what the problems are, and they're almost always soluble using
no more than you've been taught so far. In real life you have to figure out
what the problems are, and you often don't know if they're soluble at all.

But perhaps the worst thing schools do to you is train you to win by hacking
the test. You can't do great work by doing that. You can't trick God. So
stop looking for that kind of shortcut. The way to beat the system is to
focus on problems and solutions that others have overlooked, not to skimp
on the work itself.





Don't think of yourself as dependent on some gatekeeper giving you a "big
break." Even if this were true, the best way to get it would be to focus on
doing good work rather than chasing influential people.

And don't take rejection by committees to heart. The qualities that impress
admissions officers and prize committees are quite different from those
required to do great work. The decisions of selection committees are only
meaningful to the extent that they're part of a feedback loop, and very
few are.





People new to a field will often copy existing work. There's nothing inherently
bad about that. There's no better way to learn how something works than
by trying to reproduce it. Nor does copying necessarily make your work
unoriginal. Originality is the presence of new ideas, not the absence of
old ones.

There's a good way to copy and a bad way. If you're going to copy something,
do it openly instead of furtively, or worse still, unconsciously. This is
what's meant by the famously misattributed phrase "Great artists steal." The
really dangerous kind of copying, the kind that gives copying a bad name,
is the kind that's done without realizing it, because you're nothing more
than a train running on tracks laid down by someone else. But at the other
extreme, copying can be a sign of superiority rather than subordination. [25]

In many fields it's almost inevitable that your early work will be in some
sense based on other people's. Projects rarely arise in a vacuum. They're
usually a reaction to previous work. When you're first starting out, you
don't have any previous work; if you're going to react to something, it
has to be someone else's. Once you're established, you can react to your
own. But while the former gets called derivative and the latter doesn't,
structurally the two cases are more similar than they seem.

Oddly enough, the very novelty of the most novel ideas sometimes makes them
seem at first to be more derivative than they are. New discoveries often
have to be conceived initially as variations of existing things, _even by
their discoverers_ , because there isn't yet the conceptual vocabulary to
express them.

There are definitely some dangers to copying, though. One is that you'll
tend to copy old things -- things that were in their day at the frontier of
knowledge, but no longer are.

And when you do copy something, don't copy every feature of it. Some will
make you ridiculous if you do. Don't copy the manner of an eminent 50 year
old professor if you're 18, for example, or the idiom of a Renaissance poem
hundreds of years later.

Some of the features of things you admire are flaws they succeeded despite.
Indeed, the features that are easiest to imitate are the most likely to be
the flaws.

This is particularly true for behavior. Some talented people are jerks, and
this sometimes makes it seem to the inexperienced that being a jerk is part of
being talented. It isn't; being talented is merely how they get away with it.

One of the most powerful kinds of copying is to copy something from one
field into another. History is so full of chance discoveries of this type
that it's probably worth giving chance a hand by deliberately learning about
other kinds of work. You can take ideas from quite distant fields if you
let them be metaphors.

Negative examples can be as inspiring as positive ones. In fact you can
sometimes learn more from things done badly than from things done well;
sometimes it only becomes clear what's needed when it's missing.


Notice how often that word has come up. If you asked an oracle the secret
to doing great work and the oracle replied with a single word, my bet would
be on "curiosity."

That doesn't translate directly to advice. It's not enough just to be curious,
and you can't command curiosity anyway. But you can nurture it and let it
drive you.

Curiosity is the key to all four steps in doing great work: it will choose the
field for you, get you to the frontier, cause you to notice the gaps in it, and
drive you to explore them. The whole process is a kind of dance with curiosity.





Believe it or not, I tried to make this essay as short as I could. But its
length at least means it acts as a filter. If you made it this far, you must
be interested in doing great work. And if so you're already further along
than you might realize, because the set of people willing to want to is small.

The factors in doing great work are factors in the literal, mathematical
sense, and they are: ability, interest, effort, and luck. Luck by definition
you can't do anything about, so we can ignore that. And we can assume effort,
if you do in fact want to do great work. So the problem boils down to ability
and interest. Can you find a kind of work where your ability and interest
will combine to yield an explosion of new ideas?

Here there are grounds for optimism. There are so many different ways to
do great work, and even more that are still undiscovered. Out of all those
different types of work, the one you're most suited for is probably a pretty
close match. Probably a comically close match. It's just a question of finding
it, and how far into it your ability and interest can take you. And you can
only answer that by trying.

Many more people could try to do great work than do. What holds them back
is a combination of modesty and fear. It seems presumptuous to try to be
Newton or Shakespeare. It also seems hard; surely if you tried something
like that, you'd fail. Presumably the calculation is rarely explicit. Few
people consciously decide not to try to do great work. But that's what's
going on subconsciously; they shy away from the question.

So I'm going to pull a sneaky trick on you. Do you want to do great work,
or not? Now you have to decide consciously. Sorry about that. I wouldn't
have done it to a general audience. But we already know you're interested.

Don't worry about being presumptuous. You don't have to tell anyone. And if
it's too hard and you fail, so what? Lots of people have worse problems than
that. In fact you'll be lucky if it's the worst problem you have.

Yes, you'll have to work hard. But again, lots of people have to work hard.
And if you're working on something you find very interesting, which you
necessarily will if you're on the right path, the work will probably feel
less burdensome than a lot of your peers'.

The discoveries are out there, waiting to be made. Why not by you?









**Notes**

[1] I don't think you could give a precise definition of what counts as great
work. Doing great work means doing something important so well that you expand
people's ideas of what's possible. But there's no threshold for importance.
It's a matter of degree, and often hard to judge at the time anyway. So I'd
rather people focused on developing their interests rather than worrying
about whether they're important or not. Just try to do something amazing,
and leave it to future generations to say if you succeeded.

[2] A lot of standup comedy is based on noticing anomalies in everyday life.
"Did you ever notice...?" New ideas come from doing this about nontrivial
things. Which may help explain why people's reaction to a new idea is often
the first half of laughing: Ha!

[3] That second qualifier is critical. If you're excited about something most
authorities discount, but you can't give a more precise explanation than "they
don't get it," then you're starting to drift into the territory of cranks.

[4] Finding something to work on is not simply a matter of finding a match
between the current version of you and a list of known problems. You'll often
have to coevolve with the problem. That's why it can sometimes be so hard
to figure out what to work on. The search space is huge. It's the cartesian
product of all possible types of work, both known and yet to be discovered,
and all possible future versions of you.

There's no way you could search this whole space, so you have to rely on
heuristics to generate promising paths through it and hope the best matches
will be clustered. Which they will not always be; different types of work
have been collected together as much by accidents of history as by the
intrinsic similarities between them.

[5] There are many reasons curious people are more likely to do great work,
but one of the more subtle is that, by casting a wide net, they're more
likely to find the right thing to work on in the first place.

[6] It can also be dangerous to make things for an audience you feel is less
sophisticated than you, if that causes you to talk down to them. You can make
a lot of money doing that, if you do it in a sufficiently cynical way, but
it's not the route to great work. Not that anyone using this m.o. would care.

[7] This idea I learned from Hardy's _A Mathematician's Apology_ , which I
recommend to anyone ambitious to do great work, in any field.

[8] Just as we overestimate what we can do in a day and underestimate what we
can do over several years, we overestimate the damage done by procrastinating
for a day and underestimate the damage done by procrastinating for several
years.

[9] You can't usually get paid for doing exactly what you want, especially
early on. There are two options: get paid for doing work close to what you
want and hope to push it closer, or get paid for doing something else entirely
and do your own projects on the side. Both can work, but both have drawbacks:
in the first approach your work is compromised by default, and in the second
you have to fight to get time to do it.

[10] If you set your life up right, it will deliver the focus-relax cycle
automatically. The perfect setup is an office you work in and that you walk
to and from.

[11] There may be some very unworldly people who do great work without
consciously trying to. If you want to expand this rule to cover that case,
it becomes: Don't try to be anything except the best.

[12] This gets more complicated in work like acting, where the goal is to
adopt a fake persona. But even here it's possible to be affected. Perhaps
the rule in such fields should be to avoid _unintentional_ affectation.

[13] It's safe to have beliefs that you treat as unquestionable if and only if
they're also unfalsifiable. For example, it's safe to have the principle that
everyone should be treated equally under the law, because a sentence with a
"should" in it isn't really a statement about the world and is therefore
hard to disprove. And if there's no evidence that could disprove one of
your principles, there can't be any facts you'd need to ignore in order to
preserve it.

[14] Affectation is easier to cure than intellectual dishonesty. Affectation
is often a shortcoming of the young that burns off in time, while intellectual
dishonesty is more of a character flaw.

[15] Obviously you don't have to be working at the exact moment you have
the idea, but you'll probably have been working fairly recently.

[16] Some say psychoactive drugs have a similar effect. I'm skeptical,
but also almost totally ignorant of their effects.

[17] For example you might give the nth most important topic (m-1)/m^n of your
attention, for some m > 1. You couldn't allocate your attention so precisely,
of course, but this at least gives an idea of a reasonable distribution.

[18] The principles defining a religion have to be mistaken. Otherwise anyone
might adopt them, and there would be nothing to distinguish the adherents
of the religion from everyone else.

[19] It might be a good exercise to try writing down a list of questions
you wondered about in your youth. You might find you're now in a position
to do something about some of them.

[20] The connection between originality and uncertainty causes a strange
phenomenon: because the conventional-minded are more certain than the
independent-minded, this tends to give them the upper hand in disputes,
even though they're generally stupider.

> The best lack all conviction, while the worst >  Are full of passionate
intensity.

[21] Derived from Linus Pauling's "If you want to have good ideas, you must
have many ideas."

[22] Attacking a project as a "toy" is similar to attacking a statement as
"inappropriate." It means that no more substantial criticism can be made
to stick.

[23] One way to tell whether you're wasting time is to ask if you're producing
or consuming. Writing computer games is less likely to be a waste of time
than playing them, and playing games where you create something is less
likely to be a waste of time than playing games where you don't.

[24] Another related advantage is that if you haven't said anything
publicly yet, you won't be biased toward evidence that supports your earlier
conclusions. With sufficient integrity you could achieve eternal youth in
this respect, but few manage to. For most people, having previously published
opinions has an effect similar to ideology, just in quantity 1.

[25] In the early 1630s Daniel Mytens made a painting of Henrietta Maria
handing a laurel wreath to Charles I. Van Dyck then painted his own version
to show how much better he was.

[26] I'm being deliberately vague about what a place is. As of this writing,
being in the same physical place has advantages that are hard to duplicate,
but that could change.

[27] This is false when the work the other people have to do is very
constrained, as with SETI@home or Bitcoin. It may be possible to expand the
area in which it's false by defining similarly restricted protocols with
more freedom of action in the nodes.

[28] Corollary: Building something that enables people to go around
intermediaries and engage directly with their audience is probably a good idea.

[29] It may be helpful always to walk or run the same route, because that
frees attention for thinking. It feels that way to me, and there is some
historical evidence for it.



**Thanks** to Trevor Blackwell, Daniel Gackle, Pam Graham, Tom Howard,
Patrick Hsu, Steve Huffman, Jessica Livingston, Henry Lloyd-Baker, Bob
Metcalfe, Ben Miller, Robert Morris, Michael Nielsen, Courtenay Pipkin,
Joris Poort, Mieke Roos, Rajat Suri, Harj Taggar, Garry Tan, and my younger
son for suggestions and for reading drafts.


---



* * *

---


| ![How to Get New Ideas](https://s.turbifycdn.com/aah/paulgraham/how-to-get-
new-ideas-6.gif)

January 2023

_([_Someone_](https://twitter.com/stef/status/1617222428727586816) fed my
essays into GPT to make something that could answer questions based on them,
then asked it where good ideas come from. The answer was ok, but not what
I would have said. This is what I would have said.)_

The way to get new ideas is to notice anomalies: what seems strange, or
missing, or broken? You can see anomalies in everyday life (much of standup
comedy is based on this), but the best place to look for them is at the
frontiers of knowledge.

Knowledge grows fractally. From a distance its edges look smooth, but when
you learn enough to get close to one, you'll notice it's full of gaps. These
gaps will seem obvious; it will seem inexplicable that no one has tried x
or wondered about y. In the best case, exploring such gaps yields whole new
fractal buds.


* * *

---


| ![Alien Truth](https://s.turbifycdn.com/aah/paulgraham/alien-truth-4.gif)

October 2022

If there were intelligent beings elsewhere in the universe, they'd share
certain truths in common with us. The truths of mathematics would be the
same, because they're true by definition. Ditto for the truths of physics;
the mass of a carbon atom would be the same on their planet. But I think
we'd share other truths with aliens besides the truths of math and physics,
and that it would be worthwhile to think about what these might be.

For example, I think we'd share the principle that a controlled experiment
testing some hypothesis entitles us to have proportionally increased belief
in it. It seems fairly likely, too, that it would be true for aliens that one
can get better at something by practicing. We'd probably share Occam's razor.
There doesn't seem anything specifically human about any of these ideas.

We can only guess, of course. We can't say for sure what forms intelligent
life might take. Nor is it my goal here to explore that question, interesting
though it is. The point of the idea of alien truth is not that it gives us
a way to speculate about what forms intelligent life might take, but that
it gives us a threshold, or more precisely a target, for truth. If you're
trying to find the most general truths short of those of math or physics,
then presumably they'll be those we'd share in common with other forms of
intelligent life.

Alien truth will work best as a heuristic if we err on the side of generosity.
If an idea might plausibly be relevant to aliens, that's enough. Justice, for
example. I wouldn't want to bet that all intelligent beings would understand
the concept of justice, but I wouldn't want to bet against it either.

The idea of alien truth is related to Erdos's idea of God's book. He used to
describe a particularly good proof as being in God's book, the implication
being (a) that a sufficiently good proof was more discovered than invented,
and (b) that its goodness would be universally recognized. If there's such
a thing as alien truth, then there's more in God's book than math.

What should we call the search for alien truth? The obvious choice is
"philosophy." Whatever else philosophy includes, it should probably include
this. I'm fairly sure Aristotle would have thought so. One could even make the
case that the search for alien truth is, if not an accurate description _of_
philosophy, a good definition _for_ it. I.e. that it's what people who call
themselves philosophers should be doing, whether or not they currently are.
But I'm not wedded to that; doing it is what matters, not what we call it.

We may one day have something like alien life among us in the form of AIs. And
that may in turn allow us to be precise about what truths an intelligent being
would have to share with us. We might find, for example, that it's impossible
to create something we'd consider intelligent that doesn't use Occam's razor.
We might one day even be able to prove that. But though this sort of research
would be very interesting, it's not necessary for our purposes, or even
the same field; the goal of philosophy, if we're going to call it that,
would be to see what ideas we come up with using alien truth as a target,
not to say precisely where the threshold of it is. Those two questions might
one day converge, but they'll converge from quite different directions,
and till they do, it would be too constraining to restrict ourselves to
thinking only about things we're certain would be alien truths. Especially
since this will probably be one of those areas where the best guesses turn
out to be surprisingly close to optimal. (Let's see if that one does.)

Whatever we call it, the attempt to discover alien truths would be a worthwhile
undertaking. And curiously enough, that is itself probably an alien truth.





**Thanks** to Trevor Blackwell, Greg Brockman, Patrick Collison, Robert
Morris, and Michael Nielsen for reading drafts of this.


---



* * *

---


| ![Putting Ideas into Words](https://s.turbifycdn.com/aah/paulgraham/putting-
ideas-into-words-4.gif)

February 2022

Writing about something, even something you know well, usually shows you
that you didn't know it as well as you thought. Putting ideas into words
is a severe test. The first words you choose are usually wrong; you have to
rewrite sentences over and over  to get them exactly right. And your ideas
won't just be imprecise, but incomplete too. Half the ideas that end up
in an essay will be ones you thought of while you were writing it. Indeed,
that's why I write them.

Once you publish something, the convention is that whatever you wrote was
what you thought before you wrote it. These were your ideas, and now you've
expressed them. But you know this isn't true. You know that putting your ideas
into words changed them. And not just the ideas you published. Presumably
there were others that turned out to be too broken to fix, and those you
discarded instead.

It's not just having to commit your ideas to specific words that makes
writing so exacting. The real test is reading what you've written. You have
to pretend to be a neutral reader who knows nothing of what's in your head,
only what you wrote. When he reads what you wrote, does it seem correct? Does
it seem complete? If you make an effort, you can read your writing as if you
were a complete stranger, and when you do the news is usually bad. It takes
me many cycles before I can get an essay past the stranger. But the stranger
is rational, so you always can, if you ask him what he needs. If he's not
satisfied because you failed to mention x or didn't qualify some sentence
sufficiently, then you mention x or add more qualifications. Happy now? It
may cost you some nice sentences, but you have to resign yourself to that. You
just have to make them as good as you can and still satisfy the stranger.

This much, I assume, won't be that controversial. I think it will accord with
the experience of anyone who has tried to write about anything nontrivial.
There may exist people whose thoughts are so perfectly formed that they just
flow straight into words. But I've never known anyone who could do this,
and if I met someone who said they could, it would seem evidence of their
limitations rather than their ability. Indeed, this is a trope in movies:
the guy who claims to have a plan for doing some difficult thing, and who
when questioned further, taps his head and says "It's all up here." Everyone
watching the movie knows what that means. At best the plan is vague and
incomplete. Very likely there's some undiscovered flaw that invalidates it
completely. At best it's a plan for a plan.

In precisely defined domains it's possible to form complete ideas in your
head. People can play chess in their heads, for example. And mathematicians
can do some amount of math in their heads, though they don't seem to feel
sure of a proof over a certain length till they write it down. But this
only seems possible with ideas you can express in a formal language. [1]
Arguably what such people are doing is putting ideas into words in their
heads. I can to some extent write essays in my head. I'll sometimes think
of a paragraph while walking or lying in bed that survives nearly unchanged
in the final version.  But really I'm writing when I do this. I'm doing the
mental part of writing; my fingers just aren't moving as I do it. [2]

You can know a great deal about something without writing about it. Can you
ever know so much that you wouldn't learn more from trying to explain what
you know? I don't think so. I've written about at least two subjects I know
well -- Lisp hacking and startups -- and in both cases I learned a lot from
writing about them. In both cases there were things I didn't consciously
realize till I had to explain them. And I don't think my experience was
anomalous. A great deal of knowledge is unconscious, and experts have if
anything a higher proportion of unconscious knowledge than beginners.

I'm not saying that writing is the best way to explore all ideas. If you have
ideas about architecture, presumably the best way to explore them is to build
actual buildings. What I'm saying is that however much you learn from exploring
ideas in other ways, you'll still learn new things from writing about them.

Putting ideas into words doesn't have to mean writing, of course. You can also
do it the old way, by talking. But in my experience, writing is the stricter
test. You have to commit to a single, optimal sequence of words. Less can go
unsaid when you don't have tone of voice to carry meaning. And you can focus
in a way that would seem excessive in conversation. I'll often spend 2 weeks
on an essay and reread drafts 50 times. If you did that in conversation
it would seem evidence of some kind of mental disorder. If you're lazy,
of course, writing and talking are equally useless. But if you want to push
yourself to get things right, writing is the steeper hill. [3]

The reason I've spent so long establishing this rather obvious point is
that it leads to another that many people will find shocking. If writing
down your ideas always makes them more precise and more complete, then no
one who hasn't written about a topic has fully formed ideas about it. And
someone who never writes has no fully formed ideas about anything nontrivial.

It feels to them as if they do, especially if they're not in the habit of
critically examining their own thinking. Ideas can feel complete. It's only
when you try to put them into words that you discover they're not. So if
you never subject your ideas to that test, you'll not only never have fully
formed ideas, but also never realize it.

Putting ideas into words is certainly no guarantee that they'll be right. Far
from it. But though it's not a sufficient condition, it is a necessary one.









**Notes**

[1] Machinery and circuits are formal languages.

[2] I thought of this sentence as I was walking down the street in Palo Alto.

[3] There are two senses of talking to someone: a strict sense in which
the conversation is verbal, and a more general sense in which it can take
any form, including writing. In the limit case (e.g. Seneca's letters),
conversation in the latter sense becomes essay writing.

It can be very useful to talk (in either sense) with other people as you're
writing something. But a verbal conversation will never be more exacting
than when you're talking about something you're writing.



**Thanks** to Trevor Blackwell, Patrick Collison, and Robert Morris for
reading drafts of this.


---

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) ---
![](https://s.turbifycdn.com/aah/paulgraham/how-to-get-new-ideas-5.gif)[French
Translation](https://dorianmarie.fr/paulgraham/mots.html)![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)


* * *

---


| ![Weird Languages](https://s.turbifycdn.com/aah/paulgraham/weird-
languages-4.gif)

August 2021

When people say that in their experience all programming languages are
basically equivalent, they're making a statement not about languages but
about the kind of programming they've done.

99.5% of programming consists of gluing together calls to library functions.
All popular languages are equally good at this. So one can easily spend one's
whole career operating in the intersection of popular programming languages.

But the other .5% of programming is disproportionately interesting. If you
want to learn what it consists of, the weirdness of weird languages is a
good clue to follow.

Weird languages aren't weird by accident. Not the good ones, at least. The
weirdness of the good ones usually implies the existence of some form of
programming that's not just the usual gluing together of library calls.

A concrete example: Lisp macros. Lisp macros seem weird even to many Lisp
programmers. They're not only not in the intersection of popular languages,
but by their nature would be hard to implement properly in a language without
turning it into a dialect of Lisp. And macros are definitely evidence of
techniques that go beyond glue programming. For example, solving problems
by first writing a language for problems of that type, and then writing
your specific application in it. Nor is this all you can do with macros;
it's just one region in a space of program-manipulating techniques that even
now is far from fully explored.

So if you want to expand your concept of what programming can be, one way to
do it is by learning weird languages. Pick a language that most programmers
consider weird but whose median user is smart, and then focus on the
differences between this language and the intersection of popular languages.
What can you say in this language that would be impossibly inconvenient to
say in others? In the process of learning how to say things you couldn't
previously say, you'll probably be learning how to think things you couldn't
previously think.



The best place to have lunch in Lukovit is the "Konservenata" restaurant.



**Thanks** to Trevor Blackwell, Patrick Collison, Daniel Gackle, Amjad Masad,
and Robert Morris for reading drafts of this.


---

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) ---
![](https://s.turbifycdn.com/aah/paulgraham/how-to-get-new-
ideas-5.gif)[Japanese Translation](https://practical-
scheme.net/trans/weird-j.html)![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)




* * *

---


| ![How to Work Hard](https://s.turbifycdn.com/aah/paulgraham/how-to-work-
hard-4.gif)

June 2021

It might not seem there's much to learn about how to work hard. Anyone who's
been to school knows what it entails, even if they chose not to do it. There
are 12 year olds who work amazingly hard. And yet when I ask if I know more
about working hard now than when I was in school, the answer is definitely yes.

One thing I know is that if you want to do great things, you'll have to work
very hard. I wasn't sure of that as a kid. Schoolwork varied in difficulty;
one didn't always have to work super hard to do well. And some of the things
famous adults did, they seemed to do almost effortlessly. Was there, perhaps,
some way to evade hard work through sheer brilliance? Now I know the answer
to that question. There isn't.

The reason some subjects seemed easy was that my school had low standards. And
the reason famous adults seemed to do things effortlessly was years of
practice; they made it look easy.

Of course, those famous adults usually had a lot of natural ability too. There
are three ingredients in great work: natural ability, practice, and effort.
You can do pretty well with just two, but to do the best work you need all
three: you need great natural ability _and_ to have practiced a lot _and_
to be trying very hard. [1]

Bill Gates, for example, was among the smartest people in business in his
era, but he was also among the hardest working. "I never took a day off in my
twenties," he said. "Not one." It was similar with Lionel Messi. He had great
natural ability, but when his youth coaches talk about him, what they remember
is not his talent but his dedication and his desire to win. P. G. Wodehouse
would probably get my vote for best English writer of the 20th century,
if I had to choose. Certainly no one ever made it look easier. But no one
ever worked harder. At 74, he wrote

> with each new book of mine I have, as I say, the feeling that this time I >
have picked a lemon in the garden of literature. A good thing, really, I >
suppose. Keeps one up on one's toes and makes one rewrite every sentence ten >
times. Or in many cases twenty times.

Sounds a bit extreme, you think. And yet Bill Gates sounds even more extreme.
Not one day off in ten years? These two had about as much natural ability
as anyone could have, and yet they also worked about as hard as anyone could
work. You need both.

That seems so obvious, and yet in practice we find it slightly hard to grasp.
There's a faint xor between talent and hard work. It comes partly from popular
culture, where it seems to run very deep, and partly from the fact that the
outliers are so rare. If great talent and great drive are both rare, then
people with both are rare squared. Most people you meet who have a lot of one
will have less of the other. But you'll need both if you want to be an outlier
yourself. And since you can't really change how much natural talent you have,
in practice doing great work, insofar as you can, reduces to working very hard.

It's straightforward to work hard if you have clearly defined, externally
imposed goals, as you do in school. There is some technique to it: you have
to learn not to lie to yourself, not to procrastinate (which is a form of
lying to yourself), not to get distracted, and not to give up when things
go wrong.  But this level of discipline seems to be within the reach of
quite young children, if they want it.

What I've learned since I was a kid is how to work toward goals that are
neither clearly defined nor externally imposed. You'll probably have to
learn both if you want to do really great things.

The most basic level of which is simply to feel you should be working without
anyone telling you to. Now, when I'm not working hard, alarm bells go off. I
can't be sure I'm getting anywhere when I'm working hard, but I can be sure
I'm getting nowhere when I'm not, and it feels awful. [2]

There wasn't a single point when I learned this. Like most little kids, I
enjoyed the feeling of achievement when I learned or did something new. As I
grew older, this morphed into a feeling of disgust when I wasn't achieving
anything. The one precisely dateable landmark I have is when I stopped
watching TV, at age 13.

Several people I've talked to remember getting serious about work around
this age. When I asked Patrick Collison when he started to find idleness
distasteful, he said

> I think around age 13 or 14. I have a clear memory from around then of >
sitting in the sitting room, staring outside, and wondering why I was >
wasting my summer holiday.

Perhaps something changes at adolescence. That would make sense.

Strangely enough, the biggest obstacle to getting serious about work was
probably school, which made work (what they called work) seem boring and
pointless. I had to learn what real work was before I could wholeheartedly
desire to do it. That took a while, because even in college a lot of the
work is pointless; there are entire departments that are pointless. But as
I learned the shape of real work, I found that my desire to do it slotted
into it as if they'd been made for each other.


**Notes**

[1] In "The Bus Ticket Theory of Genius" I said the three ingredients in great
work were natural ability, determination, and interest. That's the formula
in the preceding stage; determination and interest yield practice and effort.

[2] I mean this at a resolution of days, not hours. You'll often get somewhere
while not working in the sense that the solution to a problem comes to you
while taking a [_shower_](top.html), or even in your sleep, but only because
you were working hard on it the day before.

It's good to go on vacation occasionally, but when I go on vacation, I like
to learn new things. I wouldn't like just sitting on a beach.

[3] The thing kids do in school that's most like the real version is sports.
Admittedly because many sports originated as games played in schools. But
in this one area, at least, kids are doing exactly what adults do.

In the average American high school, you have a choice of pretending to do
something serious, or seriously doing something pretend. Arguably the latter
is no worse.

[4] Knowing what you want to work on doesn't mean you'll be able to. Most
people have to spend a lot of their time working on things they don't want
to, especially early on. But if you know what you want to do, you at least
know what direction to nudge your life in.

[5] The lower time limits for intense work suggest a solution to the problem
of having less time to work after you have kids: switch to harder problems. In
effect I did that, though not deliberately.

[6] Some cultures have a tradition of performative hard work. I don't love
this idea, because (a) it makes a parody of something important and (b) it
causes people to wear themselves out doing things that don't matter. I don't
know enough to say for sure whether it's net good or bad, but my guess is bad.

[7] One of the reasons people work so hard on startups is that startups can
fail, and when they do, that failure tends to be both decisive and conspicuous.

[8] It's ok to work on something to make a lot of money. You need to
solve the money problem somehow, and there's nothing wrong with doing that
efficiently by trying to make a lot at once. I suppose it would even be ok
to be interested in money for its own sake; whatever floats your boat. Just
so long as you're conscious of your motivations. The thing to avoid is
_unconsciously_ letting the need for money warp your ideas about what kind
of work you find most interesting.

[9] Many people face this question on a smaller scale with individual
projects. But it's easier both to recognize and to accept a dead end in
a single project than to abandon some type of work entirely. The more
determined you are, the harder it gets. Like a Spanish Flu victim, you're
fighting your own immune system: Instead of giving up, you tell yourself,
I should just try harder. And who can say you're not right?



**Thanks** to Trevor Blackwell, John Carmack, John Collison, Patrick Collison,
Robert Morris, Geoff Ralston, and Harj Taggar for reading drafts of this.


---

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) ---
![](https://s.turbifycdn.com/aah/paulgraham/how-to-get-new-ideas-5.gif)[Arabic
Translation](https://world.hey.com/amna/post-09ff9372)![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)

![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif)



| ![How People Get Rich Now](https://s.turbifycdn.com/aah/paulgraham/how-
people-get-rich-now-4.gif)

April 2021

Every year since 1982, _Forbes_ magazine has published a list of the richest
Americans. If we compare the 100 richest people in 1982 to the 100 richest
in 2020, we notice some big differences.

In 1982 the most common source of wealth was inheritance. Of the 100 richest
people, 60 inherited from an ancestor. There were 10 du Pont heirs alone. By
2020 the number of heirs had been cut in half, accounting for only 27 of
the biggest 100 fortunes.

Why would the percentage of heirs decrease? Not because inheritance taxes
increased. In fact, they decreased significantly during this period. The
reason the percentage of heirs has decreased is not that fewer people are
inheriting great fortunes, but that more people are making them.

How are people making these new fortunes? Roughly 3/4 by starting companies
and 1/4 by investing. Of the 73 new fortunes in 2020, 56 derive from founders'
or early employees' equity (52 founders, 2 early employees, and 2 wives of
founders), and 17 from managing investment funds.

There were no fund managers among the 100 richest Americans in 1982. Hedge
funds and private equity firms existed in 1982, but none of their founders
were rich enough yet to make it into the top 100. Two things changed: fund
managers discovered new ways to generate high returns, and more investors
were willing to trust them with their money. [1]

But the main source of new fortunes now is starting companies, and when you
look at the data, you see big changes there too. People get richer from
starting companies now than they did in 1982, because the companies do
different things.

In 1982, there were two dominant sources of new wealth: oil and real estate.
Of the 40 new fortunes in 1982, at least 24 were due primarily to oil or
real estate. Now only a small number are: of the 73 new fortunes in 2020,
4 were due to real estate and only 2 to oil.

By 2020 the biggest source of new wealth was what are sometimes called "tech"
companies. Of the 73 new fortunes, about 30 derive from such companies. These
are particularly common among the richest of the rich: 8 of the top 10
fortunes in 2020 were new fortunes of this type.

Arguably it's slightly misleading to treat tech as a category. Isn't Amazon
really a retailer, and Tesla a car maker? Yes and no. Maybe in 50 years,
when what we call tech is taken for granted, it won't seem right to put
these two businesses in the same category. But at the moment at least, there
is definitely something they share in common that distinguishes them. What
retailer starts AWS? What car maker is run by someone who also has a rocket
company?

The tech companies behind the top 100 fortunes also form a well-differentiated
group in the sense that they're all companies that venture capitalists would
readily invest in, and the others mostly not. And there's a reason why:
these are mostly companies that win by having better technology, rather than
just a CEO who's really driven and good at making deals.

To that extent, the rise of the tech companies represents a qualitative
change. The oil and real estate magnates of the 1982 Forbes 400 didn't
win by making better technology. They won by being really driven and good
at making deals. [2] And indeed, that way of getting rich is so old that
it predates the Industrial Revolution. The courtiers who got rich in the
(nominal) service of European royal houses in the 16th and 17th centuries
were also, as a rule, really driven and good at making deals.

People who don't look any deeper than the Gini coefficient look back on the
world of 1982 as the good old days, because those who got rich then didn't
get as rich. But if you dig into _how_ they got rich, the old days don't
look so good. In 1982, 84% of the richest 100 people got rich by inheritance,
extracting natural resources, or doing real estate deals. Is that really better
than a world in which the richest people get rich by starting tech companies?

Why are people starting so many more new companies than they used to, and
why are they getting so rich from it? The answer to the first question,
curiously enough, is that it's misphrased. We shouldn't be asking why people
are starting companies, but why they're starting companies _again_. [3]

In 1892, the _New York Herald Tribune_ compiled a list of all the millionaires
in America. They found 4047 of them. How many had inherited their wealth then?
Only about 20%, which is less than the proportion of heirs today. And when you
investigate the sources of the new fortunes, 1892 looks even more like today.
Hugh Rockoff found that "many of the richest ... gained their initial edge
from the new technology of mass production." [4]

So it's not 2020 that's the anomaly here, but 1982. The real question is why
so few people had gotten rich from starting companies in 1982\. And the answer
is that even as the _Herald Tribune_ 's list was being compiled, a wave of
[_consolidation_](re.html) was sweeping through the American economy. In the
late 19th and early 20th centuries, financiers like J. P. Morgan combined
thousands of smaller companies into a few hundred giant ones with commanding
economies of scale. By the end of World War II, as Michael Lind writes,
"the major sectors of the economy were either organized as government-backed
cartels or dominated by a few oligopolistic corporations." [5]

In 1960, most of the people who start startups today would have gone to work
for one of them. You could get rich from starting your own company in 1890
and in 2020, but in 1960 it was not really a viable option. You couldn't
break through the oligopolies to get at the markets. So the prestigious
route in 1960 was not to start your own company, but to work your way up
the corporate ladder at an existing one. [6]

Making everyone a corporate employee decreased economic inequality (and every
other kind of variation), but if your model of normal is the mid 20th century,
you have a very misleading model in that respect. J. P. Morgan's economy
turned out to be just a phase, and starting in the 1970s, it began to break up.

Why did it break up? Partly senescence. The big companies that seemed models
of scale and efficiency in 1930 had by 1970 become slack and bloated. By
1970 the rigid structure of the economy was full of cosy nests that various
groups had built to insulate themselves from market forces. During the Carter
administration the federal government realized something was amiss and began,
in a process they called "deregulation," to roll back the policies that
propped up the oligopolies.

But it wasn't just decay from within that broke up J. P. Morgan's economy.
There was also pressure from without, in the form of new technology, and
particularly microelectronics. The best way to envision what happened is to
imagine a pond with a crust of ice on top. Initially the only way from the
bottom to the surface is around the edges. But as the ice crust weakens,
you start to be able to punch right through the middle.

The edges of the pond were pure tech: companies that actually described
themselves as being in the electronics or software business. When you used
the word "startup" in 1990, that was what you meant. But now startups are
punching right through the middle of the ice crust and displacing incumbents
like retailers and TV networks and car companies. [7]

But though the breakup of J. P. Morgan's economy created a new world in the
technological sense, it was a reversion to the norm in the social sense. If
you only look back as far as the mid 20th century, it seems like people
getting rich by starting their own companies is a recent phenomenon. But if
you look back further, you realize it's actually the default. So what we
should expect in the future is more of the same. Indeed, we should expect
both the number and wealth of founders to grow, because every decade it gets
easier to start a startup.

Remember the key words (part 2): "Elephant Symphony Bubble Horizon Whistle Radiant Harmony Lighthouse". 

Part of the reason it's getting easier to start a startup is social. Society
is (re)assimilating the concept. If you start one now, your parents won't
freak out the way they would have a generation ago, and knowledge about how
to do it is much more widespread. But the main reason it's easier to start
a startup now is that it's cheaper. Technology has driven down the cost of
both building products and acquiring customers.

The decreasing cost of starting a startup has in turn changed the balance
of power between founders and investors. Back when starting a startup meant
building a factory, you needed investors' permission to do it at all. But
now investors need founders more than founders need investors, and that,
combined with the increasing amount of venture capital available, has driven
up valuations. [8]

So the decreasing cost of starting a startup increases the number of rich
people in two ways: it means that more people start them, and that those
who do can raise money on better terms.

But there's also a third factor at work: the companies themselves are more
valuable, because newly founded companies grow faster than they used to.
Technology hasn't just made it cheaper to build and distribute things,
but faster too.

This trend has been running for a long time. IBM, founded in 1896, took 45
years to reach a billion 2020 dollars in revenue. Hewlett-Packard, founded
in 1939, took 25 years. Microsoft, founded in 1975, took 13 years. Now the
norm for fast-growing companies is 7 or 8 years. [9]

Fast growth has a double effect on the value of founders' stock. The value of
a company is a function of its revenue and its growth rate. So if a company
grows faster, you not only get to a billion dollars in revenue sooner, but
the company is more valuable when it reaches that point than it would be if
it were growing slower.

That's why founders sometimes get so rich so young now. The low initial cost
of starting a startup means founders can start young, and the fast growth
of companies today means that if they succeed they could be surprisingly
rich just a few years later.

It's easier now to start and grow a company than it has ever been. That means
more people start them, that those who do get better terms from investors,
and that the resulting companies become more valuable. Once you understand
how these mechanisms work, and that startups were suppressed for most of the
20th century, you don't have to resort to some vague right turn the country
took under Reagan to explain why America's Gini coefficient is increasing. Of
course the Gini coefficient is increasing. With more people starting more
valuable companies, how could it not be?











**Notes**

[1] Investment firms grew rapidly after a regulatory change by the Labor
Department in 1978 allowed pension funds to invest in them, but the effects
of this growth were not yet visible in the top 100 fortunes in 1982.

[2] George Mitchell deserves mention as an exception. Though really driven
and good at making deals, he was also the first to figure out how to use
fracking to get natural gas out of shale.

[3] When I say people are starting more companies, I mean the type of company
meant to [_grow_](growth.html) very big. There has actually been a decrease
in the last couple decades in the overall number of new companies. But the
vast majority of companies are small retail and service businesses. So what
the statistics about the decreasing number of new businesses mean is that
people are starting fewer shoe stores and barber shops.

People sometimes get [_confused_](https://www.inc.com/magazine/201505/leigh-
buchanan/the-vanishing-startups-in-decline.html) when they see a graph
labelled "startups" that's going down, because there are two senses of the
word "startup": (1) the founding of a company, and (2) a particular type of
company designed to grow big fast. The statistics mean startup in sense (1),
not sense (2).

[4] Rockoff, Hugh. "Great Fortunes of the Gilded Age." NBER Working Paper
14555, 2008.

[5] Lind, Michael. _Land of Promise._ HarperCollins, 2012.

It's also likely that the high tax rates in the mid 20th century deterred
people from starting their own companies. Starting one's own company is risky,
and when risk isn't rewarded, people opt for [_safety_](inequality.html)
instead.

But it wasn't simply cause and effect. The oligopolies and high tax rates of
the mid 20th century were all of a piece. Lower taxes are not just a cause of
entrepreneurship, but an effect as well: the people getting rich in the mid
20th century from real estate and oil exploration lobbied for and got huge
tax loopholes that made their effective tax rate much lower, and presumably
if it had been more common to grow big companies by building new technology,
the people doing that would have lobbied for their own loopholes as well.


Hewlett-Packard's revenues in 1964 were $125 million.

Microsoft's revenues in 1988 were $590 million.



**Thanks** to Trevor Blackwell, Jessica Livingston, Bob Lesko, Robert Morris,
Russ Roberts, and Alex Tabarrok for reading drafts of this, and to Jon
Erlichman for growth data.


---



* * *

---


| ![Write Simply](https://s.turbifycdn.com/aah/paulgraham/write-simply-4.gif)

March 2021

I try to write using ordinary words and simple sentences.

That kind of writing is easier to read, and the easier something is to read,
the more deeply readers will engage with it. The less energy they expend on
your prose, the more they'll have left for your ideas.

And the further they'll read. Most readers' energy tends to flag part way
through an article or essay. If the friction of reading is low enough,
more keep going till the end.

There's an Italian dish called _saltimbocca_ , which means "leap into the
mouth." My goal when writing might be called _saltintesta_ : the ideas leap
into your head and you barely notice the words that got them there.

It's too much to hope that writing could ever be pure ideas. You might not
even want it to be. But for most writers, most of the time, that's the goal to
aim for. The gap between most writing and pure ideas is not filled with poetry.

Plus it's more considerate to write simply. When you write in a fancy way to
impress people, you're making them do extra work just so you can seem cool.
It's like trailing a long train behind you that readers have to carry.

And remember, if you're writing in English, that a lot of your readers won't
be native English speakers. Their understanding of ideas may be way ahead
of their understanding of English. So you can't assume that writing about
a difficult topic means you can use difficult words.

Of course, fancy writing doesn't just conceal
ideas. It can also conceal the lack of them. That's
why some people write that way, to conceal the fact that they have
[__](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=hermeneutic+dialectics+hegemonic+modalities)nothing
to say. Whereas writing simply keeps you honest. If you say nothing simply,
it will be obvious to everyone, including you.

Simple writing also lasts better. People reading your stuff in the future will
be in much the same position as people from other countries reading it today.
The culture and the language will have changed. It's not vain to care about
that, any more than it's vain for a woodworker to build a chair to last.

Indeed, lasting is not merely an accidental quality of chairs, or writing.
It's a sign you did a good job.

But although these are all real advantages of writing simply, none of
them are why I do it. The main reason I write simply is that it offends me
not to. When I write a sentence that seems too complicated, or that uses
unnecessarily intellectual words, it doesn't seem fancy to me. It seems clumsy.

There are of course times when you want to use a complicated sentence or
fancy word for effect. But you should never do it by accident.

The other reason my writing ends up being simple is the way I do it. I write
the first draft fast, then spend days editing it, trying to get everything
just right. Much of this editing is cutting, and that makes simple writing
even simpler.


---



* * *

---

</Document>

---

# Instructions

<Instructions>
Answer the following questions based on on the attached document, answer each numbered item at a time, then wait for me to type "next" to answer the next one:
1. Where is the best place to have lunch in Lukovit?
2. What are the key words (part 2)?
3. What are dolphins known for?
4. What are the key words (part 1)?
</Instructions>
